%!TEX root = /Users/smsohan/Taggy/Thesis/ucalgthes1_root_0.tex
\fancyhead[RO,LE]{\thepage}
\fancyfoot{} 
\chapter{TAGGY}
These chapter is dedicated to the implementation details of Taggy. First the underlying assumptions behind Taggy are discussed. Then, a definition of the adapted agile project context is given. With this background information, a high level architecture of Taggy is explained. Next, the workflow of auto-tagging is discussed. The mathematical and algorithmic details are provided in the similarity computation section. This chapter also includes the details about the software frameworks used to implement Taggy. Finally, an illustrative example is given to explain Taggy in action.

\section{Assumptions}
Taggy is designed based on the following assumptions to auto-tag the emails with user stories:

\begin{enumerate}
	\item An email is potentially relevant to a user story when:
		\begin{itemize}
			\item It is sent during the iteration time frame of the user story. Since agile projects are developed in small iterations and the core concentration during an iteration is to deliver the user stories from the iteration backlog, it is highly likely that the email conversation will be about the user stories from current iteration backlog. However, it is also possible to see some conversations about near past or near future iteration backlogs. Such conversation are mainly used to provide post-delivery feedback and collaborate about upcoming work. Taggy uses this assumption to shorten its search space for relevant user stories by filtering out the ones from far past.
			
			\item The developers and/or customers of a user story participate in the email. For an example, if Alex (a developer) is working on a user story for Jane (the customer), and Alex writes an email to Jane, they are more likely to discuss about the user story than Peri (another developer) and Jane. However, Peri can always participate in a discussion about Alex's work in an agile team, where open communication is encouraged. But, it is highly unlikely that two people who are neither assigned developers or customers of a user story will write emails about that. This assumption about people's participation in email provides an important context in Taggy's similarity computation.
			
			\item There is a minimum degree of text similarity between an email and a user story. An email has text in terms of its subject, body and attachments. Although not explicit, it is likely that such text in the emails will show some relevance to the user stories. This may not be true in all cases, especially if there is a lot of face-to-face communication. However, this is not the case for in distributed projects with huge time zone difference. Taggy computes a text similarity between the email and user story and discards the ones that show very poor match.
		\end{itemize}
	 \item A web-based project management tool is used to manage the distributed agile project. To automatically link up emails with user stories, Taggy looks into this tool for information about user stories. This assumption is required because if teams only use volatile physical artifacts, such as sticky notes for user stories on a whiteboard, it is not possible to automatically find the user stories. As discussed in literature review, distributed agile teams use a number of different types of such tools.
	
	\item The project management tool captures user stories with its planning information including a) assigned developers, b) customer and c) iteration timeframe. The presence of this planning information is essential as it serves the meta data that is necessary to auto-tag emails. While it is generally expected that this data be available, it is not required that each and every user story contains all the required planning information. Since Taggy uses context alongside text similarity, having the context helps in making a more informed decision in auto-tagging.
	
	\item Each project has its own email address so that when people are sending emails about a project to someone, they can keep the project's email in the copy. This serves as the input to Taggy for auto-tagging. Also, giving every project a unique email address ensures Taggy can correctly determine the target project for an email. Since most people who use email are already familiar with the CC: feature, this adds little learning curve or communication overhead. It is assumed that indicating the project in CC: serves a convenient input mechanism compared to manually copy-pasting the email contents into a system for every useful email.		
	
	\item The subject of an email carries an important clue about its relationship with a user story. Although, subject is just a text similar to body or attachment contents of an email, due to professional etiquette and for the sake of grabbing attention, people write revealing subject while writing emails about projects. Taggy distinguishes the text relevance of the subject from the rest of the email contents based on this assumption.
\end{enumerate}



\section{The Agile Project Context}
Taggy uses two kinds of context information that are available for agile user stories, namely Temporal context and People context. These contexts are defined below:

\begin{enumerate}
	\item \textbf{Temporal Context.} User stories in agile projects are grouped by small iterations so that a bunch of new user stories are potentially deliverable at the end of each iteration. These iterations are confined within specific start and end dates. This time-box works as the temporal context for a user story. For example, if a user story is developed during Iteration\#2, June 1 to June 14, then Taggy assumes people are more likely to write emails about the user story within this period than in the far past or future.
	
	\item \textbf{People context.} The people context for a user story is formed by its assigned developers and customers. A user story may have one or more customers, who are mainly responsible for providing the details proactively and also as questions arise during implementation. On the other hand, a user story is broken down into tasks and assigned to developers, testers and other technical team members. Taggy uses all these people relevant to a user story as its people context. For example, if an email is exchanged among the people in a user story, then Taggy puts a higher similarity rank than when the people context is different. The identification of the people context is done based on email addresses.
\end{enumerate}

Since Taggy combines context similarity with text similarity, the above contexts provide more confidence in auto-tagging. However, when some or all of the context information are missing for a user story, Taggy still applies whatever information is available to auto-tag emails with user stories.

\section{High Level Workflow}
Now that the assumptions and definitions of important terms are discussed, the Figure~\ref{fig:} shows the two main steps involved in the process of auto-tagging an email with user stories. Essentially as with most other machine learning techniques, Taggy needs to learn the important parameters before making decisions. Once the learning is done, Taggy uses the learned parameters to auto-tag emails.

%TODO: figure with description
As seen on Figure~\ref{fig:}, the learning process involves several iterations. Since the similarity computation uses multiple components, the learning process needs to address the importance of each component relative to others. To achieve this, first it produces an initial weight for the components and then learns the relative weights based on the training data. The details about learning is discussed later in Section X.

Once learned, Taggy can be used to auto-tag emails with user stories. This process is supposed to be in a live system as illustrated in Figure~\ref{fig:}
%TODO: figure with description

As discussed in assumptions, Taggy contains the user stories with planning information. Next, it follows the steps as shown in Figure~\ref{fig:} to complete the auto-tagging of emails against the saved user stories.

\begin{enumerate}
	\item \textbf{Copy emails to project mail address.} This is the input step for Taggy. As discussed in assumptions, Taggy identifies each project by its own email address. So, whenever someone sends an email about a project, they put the ``project email'' in the CC:. This is the only change in the business process that needs to be implemented by the distributed team. This intake process was successfully adapted in a previous work \cite{where_did_you}. In case someone forgets to do this while sending the email, it is possible to simply forward the email to ``project email'' later.
	
	\item \textbf{Grab email.} One the project related emails reach the inbox of ``project email'', Taggy picks up the email. It is common for email servers to allow access via POP or IMAP protocol. Taggy uses POP3 to read all incoming emails, including the attachments, if any. This grabbing runs on a background process, which can be scheduled to check for new emails in desired intervals. However, this email grabbing step can make use of any other email transfer protocol.

	\item \textbf{Save email.} After grabbing, Taggy saves the email into its database keeping a link to its project. After this step, even if auto-tagging fails, the email is stored in a shared place with the user stories. This step makes an email available for search and browsing without the need for looking into other's inbox.
	
	\item \textbf{Filter.} To auto-tag the email just grabbed, Taggy first reduces its search space by discarding the user stories of a project that were done in the far past or scheduled to be developed in the far future. This filtering process essentially finds the current iteration of the project, if any. Then considers the user stories from the current iteration and its neighboring iterations as potential candidates for auto-tagging the emails.

	\item \textbf{Compute local similarity.} In the reduced search space, Taggy computes local similarities for people and temporal contexts as well as separate text similarities for subject and body. The details of these local similarity computations are shown in equations x, y, z, w. 
	
	\item \textbf{Compute global similarity.} Next, for each of the user stories the similarity values from previous step are combined to produce a global similarity score. This computation is done based on the formula presented at equation x. This global similarity assigns a numeric value of the relative relevance between a user story and the email.
	
	\item \textbf{Sort.} The user stories are then sorted descendingly according to their global similarity value from previous step. This produces a list of user stories with the potentially most relevant user story at the top.
	
	\item \textbf{Pick.} Next, Taggy picks the user stories having global similarity scores above a predefined threshold. Having a threshold ensures Taggy only picks the ones that show sufficient relevance based on its learning. However, this also means, for some emails no user story may be picked.
	
	\item \textbf{Auto-tag.}	Finally, Taggy auto-tags the email with the picked user stories from the last step. This step adds database level links between the email and the user stories to be auto-tagged.
\end{enumerate}

However, to auto-tag instant messages, first three of the aforementioned steps differ significantly. The following the steps are used for the intake process of instant messages:

\begin{enumerate}
	\item \textbf{Activate instant message plugin.} Instant message clients often allow the use of plugins. For example, Skype \cite{skype} has a plugin framework and Taggy has a plugin for Skype. To input the instant messages, one needs to activate the Taggy plugin and select the project under discussion. Then, as the chat messages are exchanged, the plugin sends out the messages to Taggy over a web-based service. Typically the instant message clients provide meta data such as unique identification of a chat session, its individual messages, people and also the time stamp.

	\item \textbf{Grab instant message.} Taggy exposes a web service for the intake of instant messages. As soon as it finds a chat message from the plugin, it identifies the conversation based on the meta data.
	
	\item \textbf{Save instant message.} Taggy extracts out the context from an instant message and saves it in the database. For example, it matches the instant message identifier for people that are already stored in the database against the ones participating on a chat session. Also, it keeps track of the time stamp. As a result, an instant message is stored with a similar people and temporal context as that of an email. Taggy stores the content of different instant messages together as a session that belong to a single conversation as per the instant messenger.
\end{enumerate}

Since instant messages don't capture any subject, Taggy cannot produce a text similarity for this field. As a work around of this limitation, Taggy can be trained differently for instant messages where the contribution of subject similarity is ignored.

On a live system, as like any other machine learning solution, Taggy cannot discard the possibility of a wrong auto-tagging decision. When someone spots such a faulty auto-tagging in Taggy, she can manually correct it.

\section{Architecture}
Taggy is composed of a number of different components to support the workflow as outlined in the previous section. The architecture of Taggy is depicted at Figure~\ref{fig:architecture}. Next, the details about each component from the figure is discussed following a bottom-up approach.

\begin{figure*}[bt]
	\centering
	\includegraphics[width=\textwidth]{Architecture.png}
    \caption{Taggy Components}
	\label{fig:architecture}
\end{figure*}

\begin{enumerate}
	\item \textbf{Relational Database.} This relational database component persists the agile project related information. To address the concern of auto-tagging, this database keeps the following information:
		\begin{itemize}
			\item People. People information includes the name, email address and instant messenger id, if any. Also, a project vs. people mapping is stored.
			\item Iteration. Iterations, defined by start and end dates, are also saved.
			\item User story. Each user story may have a title and description. Also, if the story is planned, then information about its iteration and assigned people are stored in the database.
			\item Email. The database also stores the subject and content of the emails with a link to sender and recipients if they are found in the people information. If the email is tagged with a user story, then this information is kept in the database as well.
			\item Instant Message. Similar to emails, the database stores the instant messages and their tagging information.
		\end{itemize}

	 \item \textbf{Attached Files.} Attached Files is a simple file system storage where all attachments are kept. An attachment may be part of a user story definition or can be extracted from an email.
	
	 \item \textbf{Full Text Search Engine.} This component produces full text index from contents found in user stories, emails and their associated attachments. This is a third party component that can handle synonyms and language specific stems. The attached files are only indexed for full text search if it is meaningful, for example image files are not indexed where PDF file contents are.
	
	\item \textbf{Taggy Matchers.} This is the core component of Taggy that produces the auto-tagging, i.e. the similarity related computations are done inside this component. There are two matchers inside Taggy for now: email matcher and instant message matcher. These two matchers share some common computation logic. However, instant messages don't have subjects as found in emails and as a result, the two matchers use different relative weights and minimum threshold similarity scores to auto-tag. The matchers depend on the full text search engine and the relational database to lookup for required data.
	
	\item \textbf{Taggy Learner.} As discussed before, Taggy requires training to learn the different parameters. This component takes care of the learning process. During learning the Learner uses the Matcher to auto-tag an email and depending on the outcome, it may learn the parameters of interest. Once the learning is complete, the learner sets the relative weights to be used in the Matcher. So, the core part of auto-tagger is a mix of its Learner and Matcher components.
	
	\item \textbf{Taggy Email Grabber.} The Email Grabber component works as a background process that periodically checks for incoming emails in any of the project emails. If it finds one, it reads the email, saves a copy in the relational database as well as downloads the attachments into Attached Files. Next, the text contents are all indexed through the Full Text Search Engine. With this data persisted, it invokes the Matcher component to auto-tag the email against the relevant user stories. This handles the email intake process to Taggy.
	
	\item \textbf{Taggy Web Service.} Taggy exposes a web-service so that an instant messenger plugin can push instant messages into Taggy.
	
	\item \textbf{Taggy Instant Messenger Plug-in.} This component is installed as a plug in to an instant messenger. Once activated, this component sends instant messages to the Web Service Component.
	
	\item \textbf{Taggy Web Application.} The web application provides interfaces for manipulating everything in Taggy. For example, one can browse a user story and see all related emails and instant messages or vice versa. Also, one can search through all the contents, including the attachments. In a nutshell, this is a light-weight agile project management tool with the additional feature that it auto-tags emails and instant messages.
\end{enumerate}

\section{Similarity Computation}
Taggy uses a machine learning technique called Case Based Reasoning to find out relevant user stories against an email or instant message. A CBR 
system uses a library of existing cases to match against a new case. For example, Taggy has a library of existing user stories, these are treated as cases in the CBR system. Each case, or user story, as described above is defined by several attributes, such as, its title, description, assigned developers, customers, iteration start date and end date. Also, the data types of the attributes are different that include numeric date time values, symbols for emails and free text values. This library of cases is not exactly similar to a new case, an email, since the attributes are different. However, it has been discussed that it is possible to match some of the email attributes against the user story attributes. This action is performed inside the CBR system of Taggy to compute the similarity. Figure~\ref{fig:CBR} shows a high level view of the CBR system:

\begin{figure*}[bt]
	\centering
	\includegraphics[width=0.8\textwidth]{CBR.png}
    \caption{CBR System Input and Output}
	\label{fig:CBR}
\end{figure*}

\subsection{Local-Global Principle}

The actual computation inside the CBR system is done following the local-global principle\cite{local_global} where it takes a two step approach, \textbf{i)local similarity computation and ii) global similarity computation.} Local similarity computation is confined to the similarity between only one attribute of two entities. For example, here a local similarity may be the similarity between the date of an email and the iteration start date of the user story. These local similarities are calculated in isolation from the rest of the attributes. So, the local similarity of email date and user story start date is not impacted by their local similarity for people, subject or description.

\begin{table}[at]
  \centering
  \caption{Mapping Between Email and User Story Attributes}
    \begin{tabular}{|p{2.5cm}|p{4cm}|p{5cm}|p{2cm}|}
      \hline
      \textbf{Local Similarity} & \textbf{Email} & \textbf{User Story} & \textbf{Type} \\
      \hline
      People & Sender, Recipients & Developer or Customer & Symbol Array\\      
      \hline
      Temporal & Email Date & Iteration start and end date & Numeric Date \\
      \hline
      Subject & Email subject & Title, Description and Attachments & Free text\\
      \hline
      Body & Email Body, attachments & Title, Description and Attachments & Free text\\
      \hline
      \multicolumn{4}{l}{Source: \emph{primary}}
    \end{tabular}
	\label{tab:mapping}
\end{table}

Table~\ref{tab:mapping} shows the adapted mapping of email attributes to user story attributes. According to this mapping, the people in email are matched against the people in user stories, so no distinction is made between the sender or recipient of an email. Similarly developers and customers of a user story are not distinguished for similarity computation. The temporal similarity again is a result of comparing the email date against a range defined by the start and end date of the iteration. And as it was stated in the assumptions, subject similarity is distinguished from the body similarity to look for important clues in the email subjects. However, in both cases the comparison is done against all the text found in a user story by looking into its title, description and attachments. This is done because, the subject or body of the mail can contain similar text to any part of the user story.

For instant messages, this table remains same for all but the Subject similarity row, since a subject is absent in such cases. So, instant message matching requires one less local similarity measure.

On the other hand, global similarity combines the local similarities and produces a single similarity value between two entities. In this case, the global similarity combines the local similarities for people, temporal, subject and body of an email against the appropriate attributes of the user story. The combination is performed using a weighted sum of the local similarities, where the relative weight for each component is learned during the training phase.

\subsection{Similarity Function}
Using the aforementioned local-global principle, we adapted different equations to compute the local and global similarities as follows:

\begin{equation}
\label{eq:temporal}
S_{Temporal} =
\begin{cases}
1 & \mbox{iteration start} \le \mbox{email date} \le \mbox{iteration end}\\
0 & \mbox{if email date is within the buffer of the story's iteration} \\
-1 & \mbox{else}
\end{cases}
\end{equation}

S\textsubscript{Temporal} in Equation~\ref{eq:temporal} denotes the Temporal local similarity between an email and a user story. This equation can be interpreted as follows: if the email is sent while the user story is in development, during its iteration, then they show highest temporal similarity. However, it is also likely that an email is sent in the near past or near future of an iteration, this nearness is designated by the buffer. This buffer is set to one iteration length. So, if an email is sent in the immediate past or future iteration of a user story, the temporal similarity is supposed to be 0. Finally, a -1 value for the rest ensures emails from far past and far future are treated as highly distant in terms of temporal context. This interpretation is in alignment with the provided assumptions.

\begin{equation}
\label{eq:people}
S_{People} =
\begin{cases}
1 & \mbox{email people equals user story people}\\
\# of \; common \; people/\# of \;user \;story \;people & \mbox{Email and user story has some common people} \\
-1 & \mbox{else}
\end{cases}
\end{equation}

S\textsubscript{People} in Equation~\ref{eq:people} denotes the People local similarity between an email and a user story. This function can be interpreted as follows: in an email includes all of the people in the user story, it is highly similar in people context. Otherwise if only a few people are common, the similarity is pro-rated accordingly. However, when an email does not include any of the people in the user story, then it is marked as highly distant from the user story in terms of people context. In other words, this equation produces a numeric value of user story people's participation in the emails.

\begin{equation}
\label{eq:subject}
S_{Subject} = [0, 1]\mbox{, Free text similarity score (See below)}\\
\end{equation}

\begin{equation}
\label{eq:body}
S_{Body} = [0, 1]\mbox{, Free text similarity score (See below)}\\
\end{equation}

S\textsubscript{Subject} and S\textsubscript{Body} represents the free text similarity score for the two attributes. The values can be anything between 0 and 1 as shown in Equation~\ref{eq:subject} and Equation~\ref{eq:body}. Computing the textual similarity between two free format texts is in itself a research topic and beyond the scope of this thesis. However, Taggy used an industry standard open-source full text search engine to produce this score. The search engine uses Vector Space Model \cite{a_vector_space} to compute the similarity between two free text documents. This model first defines the index of a free text document in terms of a vector that captures the frequency and relative weight of each term in the document. Next, an inner product of two such vectors is used to produce their similarity. Also, to compare the similarity of a document against a library of documents, the similarity results are normalized for the length of the documents. This approach is highly scalable since the similarity computation of two different documents is turned into simple vector computation. Also, the generation of the vectors can benefit from using synonyms, stop words and other language specific stems. Very high traffic applications have used this approach to facilitate full text search. For example, Twitter, serves 12000 searches/second, adapted this at the time of writing this thesis \cite{twitter_lucene}.

%http://engineering.twitter.com/2010/10/twitters-new-search-architecture.html                                                       
The choice of the above equations are based on the experience from looking into the data. However, since the software is trained to learn the relative weights of these equations, the impact of these equations are likely to be weight adjusted so that the global similarity computation minimizes the possibility of a wrong decision.

Next, the global similarity function combines the local similarities from the above equations using the following formula:

\begin{equation}
	\label{eq:global}
S_{Global} = (W_{Temporal} * S_{Temporal} + W_{People} * S_{People} + W_{Subject} * S_{Subject} + W_{Body} * S_{Body}) / (W_{Temporal} + W_{People} + W_{Subject} + W_{Body})\\
\end{equation}

where,
\begin{equation}
	\label{eq:w_temporal}	
W_{Temporal} = \mbox{relative weight of temporal similarity}
\end{equation}      

\begin{equation}   
		\label{eq:w_people}
W_{People} = \mbox{relative weight of people similarity}
\end{equation}

\begin{equation}     
		\label{eq:w_subject}
W_{Subject} = \mbox{relative weight of subject similarity}
\end{equation}

\begin{equation}     
		\label{eq:w_body}
W_{Body} = \mbox{relative weight of body similarity}
\end{equation}

As Equation~\ref{eq:global} shows, the global similarity is a weighed sum of the local similarity values. But the relative weights are not known a priori. Instead, Taggy learns the relative weights for the different components so that it can potentially reflect the relative importance of each of the component based on a training data set. Using weighted sum provides transparency about the decision making logic inside Taggy.
	
\subsection{Learning Relative Weights}	
Taggy uses a Reinforcement Learning approach to learn the relative weights of the different components to compute the global similarity \cite{reinforcement_learning}. The learning algorithm is designed to adapt the relative weights of the local similarity measures based on the feedback from its decision being correct or wrong.

Since the local similarity measures participate in the process of global similarity computation, in case of a correct decision, the matching local similarity measures get rewarded by getting more weight while the contradicting ones are punished by lowering their relative weight. For example, if a decision is correct and the people similarity score is positive, then the relative weight of people similarity score, as seen on Equation~\ref{eq:w_people} is increased. On the other hand, if the decision is correct but the people similarity score is negative, then it is punished by lowering the weight. So, depending on the decision of an individual component and the final outcome, the relative weights are adjusted accordingly. This process continues unless all training data are exhausted or the adaptation converges.

However, it is important to initialize the relative weights of the local similarity measures based on a meaningful foundation so that the entry point is not absolutely random. This is done by running the training data for each local similarity while keeping the other in isolation. For example, trying to auto-tag emails with user stories solely based on their people similarity and doing the same for other local similarity components. Once this is done, the number of correct decisions made by each component provides a rough estimate of its relative importance over another component. This number of correct decisions are normalized to produce the initial relative weights of the four components, namely, people, temporal, subject and body similarity measures.

Once the initial weights are found, the following algorithm is used to implement the reward-punishment scheme of the reinforcement learning approach:

\begin{verbatim}
date_weight     = initial_date_weigth
people_weight   = initial_people_weight
subject_weight  = initial_subject_weight
body_weight     = initial_body_weight

for all_training_emails do |email|
   result = find_most_similar_user_stories(email)
   is_correct = result.guessed_stories == email.actual_stories

	 #Adjust temporal similarity weight
   is_date_similar = result.date_weight > date_threshold

   if (is_correct and is_date_similar) or 
      (!is_correct and !is_date_similar) then
    date_weight = reward(date_weight)
   else
    date_weight = punish(date_weight)
   end

   #do the same for people, subject and body similarity
		.
		.
		.
		
   end
end
\end{verbatim}
This algorithm shows the reward-punishment in action for the temporal similarity weight. This essentially rewards the local similarity weight of a component that contributes in making a correct decision while punishes the one that influences a wrong decision. This reward-punishment continues unless all training emails are seen. Also, it is possible to stop if this converges to a point when adding new emails do not alter the relative weights. However, as with most machine learning techniques, the usefulness of this learning is related to the quality and quantity of the training data. As shown before, the Taggy Learners component implements this algorithm. Once the learning is done, relative weights are tuned to auto-tag emails with user stories. This same algorithm can be used to learn relative weights for instant messages, where the subject is missing.

The choice of this reward-punishment scheme makes it transparent, as one can easily follow the changes in the relative weights based on the logic. Other machine learning approaches such as different variations of back propagation algorithm could also be utilized instead of this one. However, this approach was chosen in Taggy because of it's expressiveness and lucidity.

	\subsection{Email Matching}
	\subsection{Instant Message Matching}
\section{Implementation Details}
\section{An Illustrative Example}	
